<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[单一职责原则的思考]]></title>
    <url>%2F2018%2F11%2F15%2FThinking%20for%20Single%20Responsibility%20Principle%2F</url>
    <content type="text"><![CDATA[单一职责原则，是面向对象设计的基本原则之一，易于理解，且十分受用。官方对此理解为：一个类应该有且只有一个变化的原因。当有多个原因导致类发生变化时，这意味着可以通过设计新的类来体现这种变化，而不是让一个已有的类变得臃肿。重新思考我们的类，让已有的类尽可能的简单化，是迭代开发中一个必要的环节。 单一职责，追求的是简单明确的设计，这种设计，不局限于类的设计，可以扩展到任何一个程序逻辑单元的设计，如函数的设计，模块的设计，工程的设计，项目的设计等。 单一职责的核心可以理解为：化整为零，将整体分解为局部的逻辑单元，不同的逻辑单元之间尽可能的相对独立，并且职责明确。例如，一个项目，可以分解为多个工程；一个工程，可以分解为多个模块；一个模块，可以分解为多个包和类；一个类，可以分解为多个属性和方法行为。设计层面的分解，可以对应到具体实现层面的分离。下面以Java Web项目为例，探讨分离的具体实现。 前后端分离在早起的Java Web开发中，MVC是一种经典的分层设计思路。通过将模型、控制和视图进行分层，不同的开发者可以专注于他们擅长的领域，如前端开发者可以专注于视图，后端开发者可以专注于逻辑控制，数据库设计者可以专注于底层数据模型的设计，层与层之间只要约定好接口和规范，就可以顺利的进行协作开发。但这样也有一个问题，模型、控制和视图这三者必须同时运行起来，整个Web工程才可以正常的启动，这对于开发调试和部署的代价都是很大的。本质上讲，视图层的职责就是负责数据的展示，不关心数据从哪里来以及数据如何加工处理。而控制层的职责是处理外部的请求并给出响应，专注于内容而不是内容的表现形式。至于模型层，其职责主要是管理持久化的数据，而并不关心数据要如何被使用。因此从职责上讲，这三者可以认为是独立的，既然是独立的，那么能否进行独立的部署呢？答案是可以的，独立的部署，意味着在开发前端视图时，并不依赖于后端的服务，只需要专注于界面的开发即可。对于后端，只需要专注于数据服务和业务逻辑。在具体实现上，前端可以基于NodeJs，Webpack或者React 组件进行开发，后端可以基于Springboot的微服务架构进行开发，两边通过Restful API 进行数据的交互，且独立开发和部署。这样，将一个Java Web项目分拆为两个工程，通过前后端分离，将给开发和维护带来很大的便利。 接口与实现分离接口和实现的分离，是Java语言倡导的基本设计哲学，通过interface和class关键字就可以看出。从单一职责的角度来讲，接口的职责就是定义对外的服务，既然是对外，那么所有的常量和方法都是public的，因此在定义接口的服务时，建议不需要带上public关键字，而专注于服务的名称和参数设计。接口可以理解为一种契约，一种协议，在此协议下，针对不同的场景，可以有不同的实现方式。协议，即签名，它是通过接口的方式定义的，接口要做的，是保证提高稳定可靠的服务，而具体的实现，交给实现类去完成就好了。从单一职责的角度，实现类的职责就是专注于接口的方法实现，换言之，如果实现类中有公共的public方法，那么最好都是接口中声明的，即@Override注解。不建议在实现类中暴露额外的public方法，如果不得不这么做，可以重新思考接口的设计，而不是实现类本身。实现类的职责很简单，就是为了实现而实现。如果不遵从接口的定义而开放过多的public方法，这将使得类的设计变得混乱，后期不利于扩展和维护。接口和实现分离的案例有很多，如Web开发中经常遇见的service层和对应的XXXImpl实现类，当需要新增一个action去处理请求时，首先考虑的不是action如何写，而是应该如何通过接口去定义服务。 业务与系统分离业务与系统的分离，是基于这样的一个事实：如果把一个Java Web工程看作一个应用系统，那么在面向业务的同时，它还有一个职责是服务于自身。简单的说，应用系统既要面向复杂灵活的业务，又得保持自身的稳定性、扩展性，等等。从开发的角度，这意味着有些代码是用于自身配置的，如权限管控，公共工具，服务器配置等，而有些代码是用于处理业务的，如查询第三方业务数据库获取数据，如按照业务规则进行文件等转换等。如果不留意，随着工程代码量的增加，渐渐的会发现，业务相关的代码和系统相关的代码都糅合在一起，这将严重影响代码的质量，以至于变得不可维护。从本质上来讲，业务相关的东西是与系统本身无关的，是外界的，是不可控的，这意味这类代码需要设计的灵活。保证灵活性的一个有效途径就是让代码尽可能的职责单一，即无侵入式设计。有一个简单的方法可以检测这种设计：前提是将所有业务相关的代码放在一个包或一个模块中，如果直接移除这个包或模块而不影响整个工程的运行，说明满足了业务与系统的分离。在具体的工程实现中，与业务相关的代码可以放在独立的包或模块中，而对于易变的业务，可以采用脚本语言编写，如python，shell，然后运行时调用即可。编程语言都有着各自的优势和不足，在处理易变的业务规则方面，脚本语言相比于强编译型语言，显得更灵活更便捷。 公共与逻辑分离公共与逻辑的分离，讲究的是不要把本可以抽离出的公共对象，放在逻辑处理的代码中。从单一职责的角度讲，公共对象就好比日常中的小工具一样，它们彼此间相互独立，它的职责就是提供逻辑处理上的帮助。对于公共的东西，往往会多个地方会用到，即拥有者全局的作用域，从实现的角度，静态类，静态方法，外部配置文件等，都可以用于描述公共对象。而逻辑，通常指的是为了实现某个功能的一段代码，对于逻辑代码，无权也并不需要维护公共的对象的定义和值域，只要使用好即可。在一个Java Web工程中，往往会涉及许多的逻辑代码，久而久之产生了许多的配置项和公共工具类，如处理字符编码，中文转拼音，Json返回值模板，邮件正文模板，数据库配置，缓存配置，Web服务器配置，本地路径配置等。 开发与生产分离单一职责原则，还体现在开发与生产的分离。开发阶段的职责，是为了能快速方便的开发。为此，在后台服务方面，可以引入Maven来管理依赖，可以引入内嵌的Tomcat来充当Web服务器，可以引入H2这样的内存数据库来做数据的持久化。在前端开发方面，可以引入webpack-dev-server充当Express服务器，可 数据模型和处理分离数据模型和数据处理，几乎在所有的Java Web应用中都显得十分重要。数据模型，侧重于数据的定义和组织，而数据处理，侧重的是数据的使用。至于数据的管理，则需要同时关注数据模型和数据处理。数据模型层面，涉及日常的数据更新和维护；数据处理层面，涉及读写操作的控制。读写控制，可以有两种思路实现，一种是代码级别做处理，将涉及读和写操作的业务代码做进一步分解，分别处理读和写。另一种思路是在数据库层吗做约束，提供不同读写权限的数据库用户给应用层使用。在现有的主流框架体系中，数据模型和数据处理大体上都是分离的，这种分离的处理方式不单单指的是Bean层和DAO层的分离，还可以用到其他的POJO对象实体中。业务对象（BO）往往对应着业务数据库的实体，持久化对象（PO）的范围更大，不限于业务对象，还可以是系统本身配置用到的对象等，值对象（VO）通常用于业务层之间的数据传递，如可以用来定义Restful API的Json响应实体，可以用来定义不同业务之间的消息实体等。在数据处理过程中，不涉及数据模型等定义，如确实有需要，考虑到其他类不会使用的情况下，可以通过内部类的方式实现。总之，模型和处理的职责都很明确，一个专注于数据结构的定义，一个专注于优雅的处理算法。 如有好想法，欢迎一起交流。]]></content>
      <tags>
        <tag>Design Pattern</tag>
        <tag>SRP</tag>
        <tag>Java Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何闭环的完成阶段性的工作]]></title>
    <url>%2F2018%2F11%2F04%2Fhow-closed-loop-done%2F</url>
    <content type="text"><![CDATA[有始有终 再小的事情也不要忘了结束。 谨小慎微 小问题随处可见，为什么要轻易忽视呢。 连续作业 任务开始了，就需要一根到底，直到关闭任务。]]></content>
  </entry>
  <entry>
    <title><![CDATA[如何有效的积累]]></title>
    <url>%2F2018%2F11%2F04%2Fhow-to-accumulate%2F</url>
    <content type="text"><![CDATA[问题，是会源源不断的变得更多。积累，需要的是持续有效的进行。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Mac Terminal管理工具介绍]]></title>
    <url>%2F2018%2F10%2F04%2Fmac-terminal-tool-introduction%2F</url>
    <content type="text"><![CDATA[Homebrew Homebrew: Mac操作系统下的软件包管理工具 基本功能；安装、卸载、查看、更新、搜索 命令： 显示所有已安装：brew list 安装：brew install git 卸载：brew uninstall git 搜索：brew search git 更新：brew update git 查看：brew info git Git Git: 版本管理和代码下载工具 基本功能：管理代码库 概念：工作区、暂存区、本地仓库、远程仓库 6大基本命令： add：增加文件到暂存区 commit：提交变化到本地仓库 push：提交到远程分支 fetch/clone：从远程分支下载 checkout：撤销和恢复 pull：取回远程仓库的变化与本地合并 SVN SVN：局域网内的版本控制工具 概念：项目仓库、工作拷贝、操作文件、标签、分支、合并 Ant Ant：工程自动化构建工具 Maven Maven：项目依赖管理工具 NPM NodeJS依赖包管理工具 Mac上如何通过命令行卸载程序？ Mac上删除程序即卸载程序 查看命令的安装路径： which mvn 对于软连接，可以通过ls命令查看真实的路径：ls -l /usr/local/bin/mvn]]></content>
  </entry>
  <entry>
    <title><![CDATA[Idea 开发工具使用]]></title>
    <url>%2F2018%2F08%2F13%2FIdea-IDE-for-Java%2F</url>
    <content type="text"><![CDATA[待完成。]]></content>
  </entry>
  <entry>
    <title><![CDATA[JPA用于数据持久化]]></title>
    <url>%2F2018%2F08%2F13%2FJPA-mapping-for-data%2F</url>
    <content type="text"><![CDATA[能不用程序员写的，尽量不用程序员去写。 规范约束和灵活配置中寻找平衡。 专注于数据和业务逻辑。 默认的数据库默认的表名默认的字段名默认的数据操作方法基于注解的配置 如何从Java类映射到数据库的结构化数据? 实体类 成员变量 成员关系 CRUD操作 自定义查询 参数传递 待完成。]]></content>
  </entry>
  <entry>
    <title><![CDATA[SVN工具用于本地版本管理]]></title>
    <url>%2F2018%2F08%2F13%2FSVN-deliverer-for-coder%2F</url>
    <content type="text"><![CDATA[待完成。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Maven工具用于项目构建和规划]]></title>
    <url>%2F2018%2F08%2F13%2FMaven-elegant-project%2F</url>
    <content type="text"><![CDATA[待完成。]]></content>
  </entry>
  <entry>
    <title><![CDATA[（四）Hadoop笔记：MacOS本地开发Mapreduce程序]]></title>
    <url>%2F2018%2F07%2F27%2Fhadoop-learn-04%2F</url>
    <content type="text"><![CDATA[本地Java IDE准备Hadoop远程访问基本Hadoop程序开发 【待完成】]]></content>
      <tags>
        <tag>Hadoop</tag>
        <tag>Mapreduce</tag>
        <tag>Eclipse</tag>
        <tag>HDFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（三）Hadoop笔记：Hadoop分布式集群搭建]]></title>
    <url>%2F2018%2F07%2F27%2Fhadoop-learn-03%2F</url>
    <content type="text"><![CDATA[Hadoop安装环境准备安装Hadoop分布式集群，对于操作系统，有一些前置条件需要满足。 JDK12345678910查看是否安装java –version解压缩jdk安装包tar -zxvf jdk-8u171-linux-x64.tar.gz -C /opt/modules配置环境变量vi /etc/profileexport JAVA_HOME="/opt/modules/jdk1.8.0_171"export PATH=$JAVA_HOME/bin:$PATH修改生效source /etc/profile 静态IP和主机检查各机器是否配置静态IP，且在hosts文件中配置IP和主机名映射。 免密码登陆检查是否可以在每一个节点上通过ssh免密码登陆到别等节点。 端口访问权限检查防火墙是否关闭，或使用firewall-cmd相关命令开启端口访问。 集群时钟同步Hadoop配置和服务安装Hadoop配置解压Hadoop安装包到指定目录/opt/modules/下，并做相应的配置。 配置JDK路径修改hadoop-env.sh、mapred-env.sh、yarn-env.sh文件中的JDK路径 1export JAVA_HOME="/opt/modules/jdk1.8.0_171" 配置core-site.xml 进入Hadoop安装目录下： vi etc/hadoop/core-site.xml12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://cluster01.kwp.com:8020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/modules/hadoop-2.6.0/data/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 说明： fs.defaultFS为NameNode的地址 hadoop.tmp.dir为hadoop临时目录，需提前创建 配置hdfs-site.xml 进入Hadoop安装目录下： vi etc/hadoop/hdfs-site.xml12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;cluster03.kwp.com:50090&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 说明： dfs.namenode.secondary.http-address 备用的NameNode dfs.permissions=false 关闭访问权限，供外部程序访问 配置slaves 进入Hadoop安装目录下： vi etc/hadoop/slaves 123cluster01.kwp.comcluster02.kwp.comcluster03.kwp.com 配置yarn-site.xml 进入Hadoop安装目录下： vi etc/hadoop/yarn-site.xml 12345678910111213141516171819202122232425262728293031323334&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;cluster02.kwp.com&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;106800&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;cluster02.kwp.com:8088&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;cluster02.kwp.com:8032&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;cluster02.kwp.com:8030&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;cluster02.kwp.com:8031&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置mapred-site.xml 进入Hadoop安装目录下： vi etc/hadoop/mapred-site.xml 1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;cluster01.kwp.com:10020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;cluster01.kwp.com:19888&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 上面配置在一个节点完成后，下一步需要通过scp命令把当前配置好的Hadoop包分发到其他节点。另外，由于是虚拟机环境，也可以通过克隆虚拟机的方式，直接克隆两外两个节点主机，而后修改相应的静态IP以及主机名。 服务安装结合节点规划，依次安装相应的服务。 节点 主机名 服务项 节点1 cluster01.kwp.com NameNode, DataNode,Nodemanager, HistoryServer 节点2 cluster02.kwp.com ResourceManager, DataNode,Nodemanager 节点3 cluster03.kwp.com SecondaryNameNode, DataNode,Nodemanager HDFS12345678查看HDFS上的目录hdfs dfs -ls /在HDFS上建立目录hdfs dfs -mkdir /out上传文件到HDFShdfs dfs -put local_file hdfs_dir显示HDFS上的文件内容hdfs dfs -cat hdfs_file NameNode和SecondNameNodeDataNode和NodemanagerResourceManager和YarnHistoryServerNameNode格式化Hadoop服务启动停止和访问服务启动 （节点1）启动HDFS start-dfs.sh （节点1）启动YARN start-yarn.sh （节点2）启动Resourcemanager yarn-daemon.sh start resourcemanager （节点3）启动日志服务器 mr-jobhistory-daemon.sh start historyserver jps 命令查看各节点上的服务。 服务监控查看Web监控页面 HDFS http://cluster01.kwp.com:50070/ YARN http://cluster02.kwp.com:8088/cluster 需要在Mac上配置hosts(/etc/hosts)，且需要开通节点上相应的端口访问权限，这样就可以在本机的浏览器进行访问。 服务终止 （节点3）终止日志服务器 mr-jobhistory-daemon.sh stop historyserver （节点2）终止Resourcemanager yarn-daemon.sh stop resourcemanager （节点1）终止YARN stop-yarn.sh （节点1）终止HDFS stop-dfs.sh]]></content>
      <tags>
        <tag>Hadoop</tag>
        <tag>HDFS</tag>
        <tag>Yarn</tag>
        <tag>DataNode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（二）Hadoop笔记：虚拟机CentOS环境准备]]></title>
    <url>%2F2018%2F07%2F27%2Fhadoop-learn-02%2F</url>
    <content type="text"><![CDATA[Linux系统安装和环境配置一般来说，虚拟机加载CentOS镜像文件后，根据向导一步步安装mini版即可。 建议： 先安装配置好一个Linux，其他2个可直接克隆得到 root用户：root/root 操作系统名称：cluster01,cluster02,cluster03 基础环境配置 主机名：便于节点之间的访问，修改主机名如下 1hostnamectl set-hostname cluster01.kwp.com 网卡：联网必备，设置为开机自启动 123vi /etc/sysconfig/network-scripts/ifcfg-eth0ONBOOT=no 改为 yesservice network restart 重启网络 sshd：SSH服务，用于远程连接和访问Linux 1234vi /etc/hosts.denyvi /etc/hosts.allow在 /etc/hosts.deny 和 /etc/hosts.allow 最后都加上一句 sshd:ALL ，保存service sshd restart 重启服务 selinux设置：关闭安全机制 123vi /etc/selinux/config将 SELINUX=enforcing 改成 SELINUX=disabled，保存init 6 重启系统 yum配置：便于联网下载软件 12345678910111213141516171819安装下载工具yum -y install wget进入yum配置文件目录cd /etc/yum.repos.d/下载网易的源配置文件(可直接去网站下载)wget http://mirrors.163.com/.help/CentOS6-Base-163.repo备份旧的配置文件mv CentOS-Base.repo CentOS-Base.repo.bak把下载的配置文件改名mv CentOS6-Base-163.repo CentOS-Base.repo清理缓存yum clean all更新缓存yum makecache更新系统yum update安装常用安装包yum -y install vimyum -y install gcc gcc-c++ make 保持本地时间与internet一致 集群中各节点的时间一致是节点间正常通信的必要条件。 安装时间同步工具：yum install -y ntpdate 同步网络时间：ntpdate time.nist.gov 时间服务器： time.nist.gov time.nuri.net 0.asia.pool.ntp.org 1.asia.pool.ntp.org 2.asia.pool.ntp.org 3.asia.pool.ntp.org 调整硬件时间：hwclock -w 查看时间： date hwclock 定时执行时间同步任务（在配置集群时才配置） crontab -e 来添加定时任务: 每隔一个小时同步一下internet1#* */1 * * * root ntpdatetime.nuri.net;hwclock -w 配置静态IP 修改 /etc/sysconfig/network-scripts/ 下的网络连接配置文件 ifcfg-ens33。 原始： 123456789101112131415TYPE="Ethernet"PROXY_METHOD="none"BROWSER_ONLY="no"BOOTPROTO="dhcp"DEFROUTE="yes"IPV4_FAILURE_FATAL="no"IPV6INIT="yes"IPV6_AUTOCONF="yes"IPV6_DEFROUTE="yes"IPV6_FAILURE_FATAL="no"IPV6_ADDR_GEN_MODE="stable-privacy"NAME="ens33"UUID="5bba20b4-ad83-452e-ac7d-076c1de0b193"DEVICE="ens33"ONBOOT="yes" 修改后： 1234567891011121314151617181920212223TYPE="Ethernet"PROXY_METHOD="none"BROWSER_ONLY="no"BOOTPROTO="static"IPADDR=192.168.32.141PREFIXO=24GATEWAY=192.168.32.2DNS1=8.8.8.8DNS2=8.8.4.4DEFROUTE="yes"IPV4_FAILURE_FATAL="no"IPV6INIT="yes"IPV6_AUTOCONF="yes"IPV6_DEFROUTE="yes"IPV6_FAILURE_FATAL="no"IPV6_ADDR_GEN_MODE="stable-privacy"NAME="ens33"UUID="5bba20b4-ad83-452e-ac7d-076c1de0b193"DEVICE="ens33"ONBOOT="yes"ZONE=public 重启网络服务： service network restart 查看IP： ip addr 配置免密码登陆 生成公钥私钥对:ssh-keygen 公钥私钥存放的目录：~/.ssh/ 目录文件说明 authorized_keys: 存放远程免密登录的公钥,主要通过这个文件记录多台机器的公钥 id_rsa: 生成的私钥文件 id_rsa.pub: 生成的公钥文件 know_hosts: 已知的主机公钥清单 如果希望ssh公钥生效需满足至少下面两个条件: .ssh目录的权限必须是700 .ssh/authorized_keys文件权限必须是600 公钥分发：ssh-copy-id -i root@cluster02.kwp.com 或者直接通过scp命令追加到对方文件中： 1scp -p ~/.ssh/id_rsa.pub root@cluster02.kwp.com: /root/.ssh/authorized_keys 登陆：ssh root@cluster02.kwp.com VMware Tools安装目的：本机设置共享文件夹，与Linux共享本地文件。 注意虚拟机的版本和Linux的版本以及Linux内核的版本，实际安装过程中往往会因为版本的原因导致VMware Tools安装失败。 预先安装依赖：1234yum install -y perlyum install -y net-toolsyum install -y gccyum install -y kernel-headers 上述升级后，可能在开机启动时产生多余的内核启动项，可通过下述方式删除多余启动项。 查询正在使用的内核：uname -a 查询系统中全部的内核：rpm -q kernel 删除多余的内核 yum remove kernel-3.10.0-327.el7.x86_64 工具安装点击虚拟机的安装VMware Tools工具，而后自动挂载安装镜像。 若发现没有挂载，可mount /dec/cdrom /media的方式手动挂载 安装文件拷贝到个人目录下，执行安装，安装过程中默认回车。123tar -xzf vmware-tools.tar.gzcd vmware-tools./vmware-tools.pl tar解压报错：归档中找不到tar: 由于前次错误，将以上次的错误状态退出。 解决办法：添加-C参数，例如 tar -zxvf ZendStudio-10.0.0-x86.tar.gz -C /home/bailin/ 安装完毕后，重启Linux，在/mnt/hgfs目录下可以看到共享的文件夹。 可能出现的问题Searching for a valid kernel header path… The path “” is not valid. 这个问题根源在于虚拟机和Linux内核版本不兼容导致。 更新本机内核：yum update kernel -y 安装所需的内核及依赖：yum install kernel-headers kernel-devel gcc make -y 重启Linux： init 6 查看本机内核和更新的内核： uname -r rpm -qa|grep –e kernel-headers –e kernel-devel 重新执行VMware Tools安装：./vmware-tools.pl 或者直接安装所需的kernel-headers and kernel-devel文件：123yum install kernel-headers-$(uname -r) kernel-devel-$( uname -r) -yyum install gcc make -yuname –r 附加 请提高vi编辑能力 请提高文本查找编辑能力，如sed,awk,grep 请熟悉make原理 请熟悉/etc下的各种配置文件]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>CentOS</tag>
        <tag>VMware Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（一）Hadoop笔记：准备工作]]></title>
    <url>%2F2018%2F07%2F27%2Fhadoop-learn-01%2F</url>
    <content type="text"><![CDATA[环境 MacOS 10.13.3 (17D47) Java version 1.8.0_151 VMware Fusion 专业版 10.0.1 CentOS-7-x86_64-Minimal-1708 Kernel 3.10.0-0-693.21.1.e17.x86_64 hadoop-2.6.0 基本Linux命令系统查询12345678910111213141516171819202122232425262728293031323334# ssh连接ssh root@cluster03.kwp.com# 查看主机名hostname# 查看端口是否连通telnet cluster03.kwp.com 8088# 查看端口当前使用情况ss -ntl# 查看Linux网络状态netstat -anp|grep 8088# 查看操作系统的发行版本号内核uname -r# 查看定时任务crontab -l# 查看IPip addr# 查询系统中全部的内核rpm -q kernel# 查看防火墙状态firewall-cmd --state# 查看Hadoop安装路径echo $HADOOP_HOME# 查看目录下所有文件大小du -sh share/doc/# 获得所有软件包安装信息rpm -qa | grep telnet# 查看服务状态service ntpd status# 查看邮件cat /var/spool/mail/root# 查看当前时间date "+%Y-%m-%d %H:%M:%S"# 显示所有本地IP地址+端口号netstat -an 目录和配置文件1234567891011121314151617181920212223242526# 系统参数设置/etc# 用户级的程序目录/opt# 系统运行时需改变的数据/var# 应用程序存放目录/usr # 用于加载各种文件系统/mnt# 所有外设所在目录/dev# 内存的映射，非真实目录/proc# hosts主机硬伤文件vi /etc/hosts# 网卡IP设置cd /etc/sysconfig/network-scripts/# 本机SSH公钥cat ~/.ssh/id_rsa.pub# 超级管理员权限控制文件cat /etc/sudoers# 系统启动时自动mount的文件列表cat /etc/fstab# 主机名cat /etc/hostname 软件安装与更新1234567891011# 安装软件yum -y install telnetyum -y install ntpdateyum -y install bash-completionyum -y install makeyum -y install kernel-headers# 更新软件yum -y update firewalldyum -y pdate kernel# 查看是否安装telnetyum list |grep telnet 基本设置和操作12345678910111213141516171819202122232425262728293031323334353637383940414243# 修改主机名hostnamectl set-hostname cluster01.kwp.com# 清除屏幕clear# 挂载设备到文件夹mount /dev/cdrom /mnt/cdrom# 添加用户adduser hadoop# 修改密码passwd hadoop# 删除用户userdel -r hadoop# 删除用户组groupdel hadoop# 优雅重启init 6# 强制重启reboot# 生成公钥私钥对ssh-keygen# 将本机公钥追加到cluster03.kwp.com主机ssh-copy-id -i cluster03.kwp.comchmod 600 authorized_keys# ntp同步网络时间ntpdate time.nist.gov# 将系统时钟同步到硬件时钟hwclock -w# 请求网页内容curl cluster02:8088/cluster# 解压缩文件到指定目录tar -xvf hadoop-2.6.0.tar -C /opt/modules# 关闭防火墙systemctl stop firewalld.service# 设置防火墙开启端口对外访问firewall-cmd --zone=public --add-port=8082/tcp --permanent# 重新加载防火墙服务firewall-cmd --zone=public --reload# sshd服务重启service sshd restart# 网络重启service network restart# 局域网主机之间互传文件scp -r yarn-site.xml cluster02.kwp.com:/opt/modules/hadoop-2.6.0/etc/hadoop/ Hadoop命令123456789101112# HDFS格式化命令hdfs namenode –format# 执行mapreduce任务bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar wordcount /input/wc.input /output# 启动Yarn任务start-yarn.sh# 启动HDFS服务start-dfs.sh# 停止resourcemanager服务yarn-daemon.sh stop resourcemanager# 启动historyserver服务mr-jobhistory-daemon.sh start historyserver 节点规划节点服务列表 节点 主机名 服务项 节点1 cluster01.kwp.com NameNode, DataNode,Nodemanager, HistoryServer 节点2 cluster02.kwp.com ResourceManager, DataNode,Nodemanager 节点3 cluster03.kwp.com SecondaryNameNode, DataNode,Nodemanager 本机虚拟机和共享目录路径：/Users/mac/Documents/Virtual Machines.localized CentOS: CentOS-7-x86_64-Minimal-1708.ISO cluster01.vmwarevm 硬盘：20G 内存：1024MB IP：192.168.32.141 连接类型：NAT sharefolder (/mnt/hgfs/sharefolder) cluster02.vmwarevm 硬盘：20G 内存：1024MB IP：192.168.32.142 连接类型：NAT sharefolder (/mnt/hgfs/sharefolder) cluster03.vmwarevm 硬盘：20G 内存：1024MB IP：192.168.32.143 连接类型：NAT sharefolder (/mnt/hgfs/sharefolder) Hadoop和JDK安装目录路径：/opt/modules/ hadoop-2.6.0 jdk1.8.0_171]]></content>
      <tags>
        <tag>Hadoop</tag>
        <tag>Linux</tag>
        <tag>Node</tag>
        <tag>MacOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么程序员写不出优雅的代码]]></title>
    <url>%2F2018%2F07%2F24%2Fwhy-not-beautiful-code%2F</url>
    <content type="text"><![CDATA[为什么程序员写不出优雅的代码呢？这个问题困惑了多年。上大学时，起初还停留在只会某种或少许的几种语言，比如C语言，Matlab，当时每多学一门语言都觉得很自豪，但学语言，主要还是为了解决老师留下的作业，至于语言背后的逻辑，还停留在一知半解的程度。后来接触了51单片机，花了整个寒假用汇编写了一个多功能电子时钟，才切身体会到用底层语言实现功能是多么的痛苦，一千多行的代码，陷入到goto中不能自拔，终于，后来过不如其然的放弃了汇编。后来又接触了Java，从面向过程到面向对象我花了很长的时间去适应，不过最后终于适应了，而且成了最钟爱的一门语言。起初，为了玩好Java，顺便入门了Html，CSS，XML，Javascript，Struts 2，Hibernate，Spring以及Mysql等，为了搭一个网站，我需要先去安装JDK，配置环境变量，安装Tomcat，安装Mysql；为了绘制网页素材，还要安装Fireworks,Dreamweaver，Flash,当时号称网页三剑客；为了方便的存取数据，还要学习SQL的语法，JDBC的基本操作，JavaBean，DAO的封装；为了处理一个个客户端的请求，还要学习Servlet，Struts2等。总之，还没有搭建起来一个像样的网站，就已经陷入到各种所谓的开发工具和依赖包里了。 我们真的需要掌握那么多的工具吗？如果是，又将如何专注于我们的代码呢？ 好的代码，需要我们有节俭意识。不要随意挥霍你的内存，你的各种可用的资源，这是我在写汇编时最深刻的教训。内存是稀缺资源，CPU也是，IO也是，一个单片机只有有限的IO，有限的时钟频率，却要实现时分复用，以欺骗性的方式实现人们喜爱的“并发执行”，又要能显示时间，又要有闹钟，又要能跑马灯，这是多么的不容易。时隔已多年，现如今高级语言大行其道，计算机资源看上去取之不尽用之不竭，但本质上底层还是跟内存、CPU、IO等资源打交道，可能短期内我们的代码还可以顺畅的跑起来，但久而久之，程序的性能自然就受到资源的制约了，到那时，若想再次对原有对代码重构，就难了。所以说，只要开始写代码，就要惦记着你的可用的资源，是资源，一定是稀缺的。 好的代码，需要在有限的时间里勤于思考和组织。很多时候，写代码只是为了完成当下的任务，着眼于当下，鲜有人想着哪些地方可能是扩展点，哪些地方很可能会被重构，当然，这也怨不得写代码的人，因为时间总是有限的，写代码本身是一件无穷无尽的工作，一味的追求完美，那么代码永远也写不完。受时间的制约，在有限的时间里去想那么多本身就不太现实，那为什么有的人能做到呢？意识，一次次踩坑后的意识。好的代码一定需要经得起实际的检验，一定需要一个不断完善的过程。有了这些过程，在过程中不断思考，积累，并认识到如何组织我们的代码，我，自然而然写出来的代码就愈见成熟了。为什么要强调组织呢？个人觉得代码本身也是有结构的有规律的，这种结果性和规律性被人们组织为设计模式或者数据结构等说法，当然更重要的在于增强我们代码的扩展性健壮性和可读性方面，扩展性是基于空间的考虑，旨在可以从代码的不同位置进行功能的扩展，从而使得代码的功能可以随着代码量呈近线性增长；健壮性是基于时间的考虑，通俗的说，要求代码不仅现在可用，而且在很长的一段时间里都可用；可读性是基于语言本身的考虑，有效沟通是语言最重要的一个用途，同样，代码也是由编程语言写出来的，那么不仅得让计算机可读，也得让未来的自己可读，让周围的他人可读，否则，又如何与他们进行沟通呢？ 为什么程序员写不出优秀的代码呢？直到工作后才发现，大多从事IT的人，其实真正花时间写代码的并不多，甚至很少。很自然的一个问题，写代码有什么用呢，写代码并不能在有限的时间内获取较大的产出和回报，这个跟企业的投入产出要求是不相符的，因此由于项目的需要，更多的是完成，即实现当下的功能即可，在此背景下，写代码就不再追求什么优雅了，“短平快”就可以了。于是乎，IT从此变得廉价，变成了工具，IT人自身的价值也大打折扣。这是个奇怪的现象，尤其是当前全行业都近乎被信息技术颠覆的时代，程序员虽然看似工资高，但一直从事着底层搬砖的苦活儿。为什么呢？这是个错误，甚至是个死循环。试想一下，程序员写了尚且可用的代码，然后很快又变得难用或者不可用，然后又开始启动新的项目开发新的尚且可用的代码，然后如此循环下去，一次次的迭代，一次次的出不来。这不是代码，更不是优雅的代码。]]></content>
      <tags>
        <tag>程序员</tag>
        <tag>代码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sublime+Hexo 优雅写博客]]></title>
    <url>%2F2018%2F07%2F16%2Fsublime-hexo-write-blog%2F</url>
    <content type="text"><![CDATA[实现思路和预期目标 “所见即所得”，打开Sublime，就可以发布博客； ”专业于博客内容“，不用关心Hexo命令的使用以及Hexo的框架代码； ”简洁唯美“，不用关心各种配置。 新建博客流程 Tools工具栏里选择发布博客，自动生成并打开博客内容模版； 填写博客元信息，并重命名博客； 完成Markdown格式的博客内容； Tools工具栏启动本地浏览或直接发布到远程仓库。 Sublime 新建博客命令命令创建的路径 Sublime &gt;&gt; Tools &gt;&gt; Build System &gt;&gt; New Build System…，新建以下内容： 12345&#123; "shell_cmd": "title=\\$(date +%H%M%S) &amp;&amp; hexo new \\$title &amp;&amp; subl /Users/mac/Documents/blog/source/_posts/\\$title.md", "working_dir": "/Users/mac/Documents/blog/", "path": "/Applications/Sublime Text.app/Contents/SharedSupport/bin:$PATH"&#125; 另存为 hexo-new-blog.sublime-build 默认博客文件和文件名为title.md，需要通过下面所设的快捷键F2进行重命名。 注意：需要结合自己本地的blog目录和Sublime安装目录进行配置shell_cmd和path。 Sublime 本地Hexo服务器启动命令命令创建的路径 Sublime &gt;&gt; Tools &gt;&gt; Build System &gt;&gt; New Build System…，新建以下内容： 1234&#123; "shell_cmd": "ps -ef|grep hexo|grep -v grep|awk '&#123;print \"kill -9 \"\\$2&#125;'|sh &amp;&amp; hexo clean &amp;&amp; hexo s", "working_dir": "/Users/mac/Documents/blog/"&#125; 另存为 hexo-start.sublime-build Sublime 发布到博客网站命令命令创建的路径 Sublime&gt;&gt;Tools&gt;&gt;Build System&gt;&gt;New Build System…，新建以下内容： 1234&#123; "shell_cmd": "hexo clean&amp;&amp;hexo g -d", "working_dir": "/Users/mac/Documents/blog/"&#125; 另存为 hexo-deploy.sublime-build Sublime 重命名快捷键 新建命令文件 打开包目录：Sublime &gt;&gt; Preferences &gt;&gt; Browser Packages… 123456789101112131415161718192021222324252627282930313233# rename_file.pyimport sublimeimport sublime_pluginimport osimport functoolsclass RenameFileCommand(sublime_plugin.WindowCommand): def run(self, paths): if paths[0] == "$file": paths[0] = self.window.active_view().file_name() branch, leaf = os.path.split(paths[0]) v = self.window.show_input_panel("New Name:", leaf, functools.partial(self.on_done, paths[0], branch), None, None) name, ext = os.path.splitext(leaf) v.sel().clear() v.sel().add(sublime.Region(0, len(name))) def on_done(self, old, branch, leaf): new = os.path.join(branch, leaf) try: os.rename(old, new) v = self.window.find_open_file(old) if v: v.retarget(new) except: sublime.status_message("Unable to rename") def is_visible(self, paths): return len(paths) == 1 感谢 https://superuser.com/questions/683766/renaming-open-files-in-sublime-text-2/684114#684114 注册快捷键 打开快捷键设置 Sublime &gt;&gt; Preferences &gt;&gt; key Bindings,添加下面配置： 12345[ &#123; "keys": ["f2"], "command": "rename_file", "args": &#123; "paths": ["$file"] &#125; &#125;] 也可使用命令来控制文件的重命名和删除，Command-Shift-P &gt;&gt; Package Control: Install Package &gt;&gt; File Rename 和 Delete Current File。 Markdown插件安装 菜单栏：Preferences &gt;&gt; Package Control &gt;&gt; Package Control:Install Package Command-Shift-P 打开Package Control,Install Package 搜索并安装 Markdown Editing即可。 如果喜欢实时预览，可以同时安装 MarkdownLivePreview。 默认MarkdownLivePreview不开启实时预览，可设置Preferences → Package Settings → MarkdownLivePreview → Setting，打开后将左边default的设置代码复制到右边User栏，找到”markdown_live_preview_on_open”:false,把false改为true Markdown Editing本身已很好用，不建议再次安装MarkdownLivePreview。 Sublime 自动保存 Ctrl+Shift+p调出命令面板 找到Preferences:Settings - Use 自定义设置失去焦点自动保存 “save_on_focus_lost”: true； 感谢 https://www.cnblogs.com/itbull/p/6182460.html]]></content>
      <tags>
        <tag>Sublime</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown+Hexo 内容呈现]]></title>
    <url>%2F2018%2F07%2F13%2Fmarkdown-hexo-content-presentation%2F</url>
    <content type="text"><![CDATA[Hexo和Next主题自带标签 内容居中 123&#123;% cq %&#125; Your content.&#123;% endcq %&#125; 引用 123&#123;% blockquote David Levithan, Wide Awake %&#125; Do not just seek happiness for yourself. &#123;% endblockquote %&#125; 插入代码块 123&#123;% codeblock %&#125; alert('Hello World!');&#123;% endcodeblock %&#125; Markdown标签新建md文稿，先通过分级标题形式建立目录结构，然后通过列表形式填充各级子目录内容。 标题 123456# 这是一级标题## 这是二级标题### 这是三级标题#### 这是四级标题##### 这是五级标题###### 这是六级标题 字体 123*这是倾斜的文字***这是加粗的文字*****这是斜体加粗的文字*** 分割线和引用 1234567分隔符：3个或3个以上的短横线或星号-------********&gt; 引用 链接 12![图片名](url “title”)[超链接名](url "title") 建议以插入网络链接的方式插入图片。 列表123- 列表内容+ 列表内容* 列表内容 列表嵌套：上一级和下一级之间敲三个空格即可。 表格123|标题1|标题2|标题3||:---|:---:|---:||居左测试文本|居中测试文本|居右测试文本| 未完待续：如何画流程图？]]></content>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 基本命令]]></title>
    <url>%2F2018%2F07%2F13%2Fgit-basic-command%2F</url>
    <content type="text"><![CDATA[概念 工作目录 本地版本库 远程版本库 设置12git config --global user.email "you@example.com"git config --global user.name "Your Name" 作业提交1234567891011git initgit add ./git commit -m "init"git remote rm origingit remote add origin git@github.com:用户名/仓库名.gitgit push -u origin master 版本恢复123git statusgit loggit checkout &lt;sha1-of-a-commit&gt; &lt;/path/to/your/file&gt; 去托管123git rm -r --cached filename git commit -m "delete"git push -u origin master .gitignore文件1ls -la]]></content>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Breeze blows]]></title>
    <url>%2F2018%2F07%2F12%2Fbreeze-blows%2F</url>
    <content type="text"><![CDATA[Codding is fun.Computer has accompanied us for many years.Friends, in this time of happiness, joy and good will to accompany you! It is the kind of mind that can see things as they are, which step by step and in a flash can realize the original nature of everything. Beginner’s mind is Zen practice in action. It is the mind that is innocent of preconceptions and expectations, judgements and prejudices. Think of beginner’s mind as the mind that faces life like a small child, full of curiosity and wonder and amazement. Steve Jobs There’s a phrase in Buddhism, ‘Beginner’s mind.’ It’s wonderful to have a beginner’s mind. The only way to do great work is to love what you do. If you haven’t found it yet, keep looking. Don’t settle. As with all matters of the heart, you’ll know when you find it. Have the courage to follow your heart and intuition. They somehow already know what you truly want to become. Everything else is secondary. Steve Jobs Created by Quippy on 2018-07-12.]]></content>
      <tags>
        <tag>code</tag>
        <tag>idea</tag>
        <tag>joy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Start with Hexo]]></title>
    <url>%2F2018%2F07%2F12%2FStart-with-hexo%2F</url>
    <content type="text"><![CDATA[More info from https://hexo.io/docs/ Create a new post1$ hexo new "My New Post" More info: Writing Run server123$ hexo serverOR$ hexo s More info: Server Generate static files123$ hexo generateOR$ hexo g More info: Generating Deploy to remote sites123$ hexo deployOR $ hexo d More info: Deployment Clean cache and output1$ hexo clean Cleans the cache file (db.json) and generated files (public).]]></content>
  </entry>
</search>
